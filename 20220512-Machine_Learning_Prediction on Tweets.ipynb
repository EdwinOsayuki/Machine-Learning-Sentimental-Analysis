{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6017886-1508-4fae-834a-e5d41e877982",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk.corpus import stopwords    # nltk -- natural language tool lit : ==> stopwords means those words that do not have much effect to our processing\n",
    "from nltk.stem.porter import PorterStemmer   # gives the root word about our words\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer # use to convert text in features data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d84c4937-8a9e-4f10-bd20-20404a150797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nexti\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87658cdf-c712-4e26-816b-7cd5987e710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# printing the stop words in english\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18b2965-ca2d-4f7b-923b-4c39f6d759e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>bihday your majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>#model   i love u take with u all the time in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>factsguide: society now    #motivation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet\n",
       "0   1      1   @user when a father is dysfunctional and is s...\n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...\n",
       "2   3      1                                bihday your majesty\n",
       "3   4      0  #model   i love u take with u all the time in ...\n",
       "4   5      1             factsguide: society now    #motivation"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3601cc0e-11c4-4b38-a224-691f0a3bc5de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d12c8365-9529-42c2-be3e-accca9c6efa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 31962 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      31962 non-null  int64 \n",
      " 1   label   31962 non-null  int64 \n",
      " 2   tweet   31962 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 749.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "768fbdbd-e720-4d35-9dd0-a75d012b9893",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id       0\n",
       "label    0\n",
       "tweet    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bef5d251-e8dc-4049-ab7e-94c7e5b43197",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18887\n",
       "1    13075\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8c4a6d2-7afd-446b-901a-9e430e638038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separating the data set\n",
    "\n",
    "tweet_column = df.drop(columns='label', axis=1)\n",
    "label_column = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e095acb-58bf-4b93-8c71-1b90aa53f1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          id                                              tweet\n",
      "0          1   @user when a father is dysfunctional and is s...\n",
      "1          2  @user @user thanks for #lyft credit i can't us...\n",
      "2          3                                bihday your majesty\n",
      "3          4  #model   i love u take with u all the time in ...\n",
      "4          5             factsguide: society now    #motivation\n",
      "...      ...                                                ...\n",
      "31957  31958  ate @user isz that youuu?ðððððð...\n",
      "31958  31959    to see nina turner on the airwaves trying to...\n",
      "31959  31960  listening to sad songs on a monday morning otw...\n",
      "31960  31961  @user #sikh #temple vandalised in in #calgary,...\n",
      "31961  31962                   thank you @user for you follow  \n",
      "\n",
      "[31962 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "print(tweet_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa557400-464a-4950-b14e-ea3d5ae0e421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        0\n",
      "2        1\n",
      "3        0\n",
      "4        1\n",
      "        ..\n",
      "31957    1\n",
      "31958    1\n",
      "31959    0\n",
      "31960    1\n",
      "31961    0\n",
      "Name: label, Length: 31962, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(label_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8017a1c3-841a-4d31-98f7-6fb7f1c55ad9",
   "metadata": {},
   "source": [
    "### Steming :\n",
    "\n",
    "Is the process of reducing a word to its root word\n",
    "\n",
    "\n",
    "example:\n",
    "actor,  actress, acting ---> act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a333d6ee-671d-4f25-9386-2129c1cbb107",
   "metadata": {},
   "outputs": [],
   "source": [
    "port_stem = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7303072-0020-4e82-8f90-0835b19e15d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "twit = tweet_column['tweet']\n",
    "\n",
    "def stemming(twit):   # creating a function called steaming\n",
    "    stemmed_content = re.sub('[^a-zA-Z]',' ', twit) # remoing characters\n",
    "    stemmed_content = stemmed_content.lower() # converting all the words to lower case\n",
    "    stemmed_content = stemmed_content.split() # splitting the words and converting it to list\n",
    "    stemmed_content = [port_stem.stem(word) for word in stemmed_content if not word in stopwords.words('english')] # performing steming; reducing each word to its root word and also removing the stop words\n",
    "    stemmed_content = ' '.join(stemmed_content) #\n",
    "    return stemmed_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "400558a4-b391-4ce4-a29b-630b086e4629",
   "metadata": {},
   "outputs": [],
   "source": [
    "steem_tweet = tweet_column['tweet'].apply(stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "803d640c-7fd5-4a69-bc88-3a590e531026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        user father dysfunct selfish drag kid dysfunct...\n",
      "1        user user thank lyft credit use caus offer whe...\n",
      "2                                           bihday majesti\n",
      "3                              model love u take u time ur\n",
      "4                                  factsguid societi motiv\n",
      "                               ...                        \n",
      "31957                                   ate user isz youuu\n",
      "31958    see nina turner airwav tri wrap mantl genuin h...\n",
      "31959             listen sad song monday morn otw work sad\n",
      "31960     user sikh templ vandalis calgari wso condemn act\n",
      "31961                                    thank user follow\n",
      "Name: tweet, Length: 31962, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(steem_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "35af9c29-6043-46c7-9891-6c86bca54aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = steem_tweet.values\n",
    "y = label_column.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f47463-2db1-43aa-be6b-762b7860c402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "069542e6-ccd5-4901-b3aa-1e4dd5ea5044",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['user father dysfunct selfish drag kid dysfunct run'\n",
      " 'user user thank lyft credit use caus offer wheelchair van pdx disapoint getthank'\n",
      " 'bihday majesti' ... 'listen sad song monday morn otw work sad'\n",
      " 'user sikh templ vandalis calgari wso condemn act' 'thank user follow']\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c06df64-6454-45da-bcb4-5382a48bab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 1 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf16c53d-18a8-45e6-a228-baa165bf42eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "###   Bag of words vectorization\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(x)\n",
    "\n",
    "#test_x_vector = vectorizer.transform(test_x)\n",
    " \n",
    "train_x_array = x.toarray()\n",
    "print(train_x_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b3bf696-ec13-4587-bfc4-6f558c3e3122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 29005)\t1\n",
      "  (0, 9012)\t1\n",
      "  (0, 7824)\t2\n",
      "  (0, 24159)\t1\n",
      "  (0, 7558)\t1\n",
      "  (0, 14711)\t1\n",
      "  (0, 23484)\t1\n",
      "  (1, 29005)\t2\n",
      "  (1, 27218)\t1\n",
      "  (1, 16405)\t1\n",
      "  (1, 6005)\t1\n",
      "  (1, 28998)\t1\n",
      "  (1, 4468)\t1\n",
      "  (1, 19699)\t1\n",
      "  (1, 30100)\t1\n",
      "  (1, 29091)\t1\n",
      "  (1, 20637)\t1\n",
      "  (1, 7120)\t1\n",
      "  (1, 10572)\t1\n",
      "  (2, 2784)\t1\n",
      "  (2, 16577)\t1\n",
      "  (3, 17712)\t1\n",
      "  (3, 16103)\t1\n",
      "  (3, 26774)\t1\n",
      "  (3, 27747)\t1\n",
      "  :\t:\n",
      "  (31958, 13194)\t1\n",
      "  (31958, 28469)\t1\n",
      "  (31958, 19094)\t1\n",
      "  (31958, 486)\t1\n",
      "  (31958, 16770)\t1\n",
      "  (31958, 24545)\t1\n",
      "  (31958, 4891)\t1\n",
      "  (31959, 23584)\t2\n",
      "  (31959, 17792)\t1\n",
      "  (31959, 17911)\t1\n",
      "  (31959, 30586)\t1\n",
      "  (31959, 25382)\t1\n",
      "  (31959, 15755)\t1\n",
      "  (31959, 20126)\t1\n",
      "  (31960, 29005)\t1\n",
      "  (31960, 5555)\t1\n",
      "  (31960, 27106)\t1\n",
      "  (31960, 24734)\t1\n",
      "  (31960, 29097)\t1\n",
      "  (31960, 4092)\t1\n",
      "  (31960, 30729)\t1\n",
      "  (31960, 173)\t1\n",
      "  (31961, 29005)\t1\n",
      "  (31961, 27218)\t1\n",
      "  (31961, 9663)\t1\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6009d-c78e-4a16-b6db-20d05228d5cc",
   "metadata": {},
   "source": [
    "### Splitting the dataset to training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f9a66934-e3a1-45d5-82be-80e717a758bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1361fe3d-f9a3-4daf-a13a-01380278673d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31962, 31307) (25569, 31307) (6393, 31307)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape, x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb990f95-7e9b-4c47-a81f-f10ed4d8a51a",
   "metadata": {},
   "source": [
    "### Training the Model : Decision Treet and Logistics Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78bad4ae-d8a6-4978-827b-d05e13361c83",
   "metadata": {},
   "source": [
    "#### Making a prediction system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd9d4c4-ea86-4fdc-a1bb-4384e5f62a76",
   "metadata": {},
   "source": [
    "### Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "334f25ae-6a81-4b8f-9e11-944d9e5a7280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for Decision Tree of the trained data :  0.96601353201142\n",
      "\n",
      "\n",
      "The Prediction is  [1]\n",
      "This is a racist or sexist tweet\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "x_train_prediction = clf.predict(x_train)\n",
    "training_score_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "print('Accuracy score for Decision Tree of the trained data : ', training_score_accuracy)\n",
    "\n",
    "#x_test_prediction = clf.predict(x_test)\n",
    "#test_score_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "#print('Accuracy score for Decision Tree of the test data : ', test_score_accuracy)\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "x_new = x_test[300]\n",
    "prediction = clf.predict(x_new)\n",
    "print('The Prediction is ', prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "    print('This is not a racist or sexist tweet')\n",
    "else:\n",
    "    print('This is a racist or sexist tweet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a2e36-b97f-4c0c-b241-8958cb3f794a",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69361137-0b56-4b8f-8c13-80f5a9affd0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the trained data :  0.8211897219288983\n",
      "\n",
      "\n",
      "The Prediction is  [1]\n",
      "This is a racist or sexist tweet\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nexti\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# accuracy score on training data\n",
    "\n",
    "x_train_prediction = model.predict(x_train)\n",
    "training_score_accuracy = accuracy_score(x_train_prediction, y_train)\n",
    "print('Accuracy score of the trained data : ', training_score_accuracy)\n",
    "\n",
    "# accuracy score on test data\n",
    "\n",
    "#x_test_prediction = model.predict(x_test)\n",
    "#test_score_accuracy = accuracy_score(x_test_prediction, y_test)\n",
    "#print('Accuracy score of the test data : ', test_score_accuracy)\n",
    "\n",
    "x_new = x_test[300]\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "prediction = model.predict(x_new)\n",
    "print('The Prediction is ', prediction)\n",
    "\n",
    "if (prediction[0] == 0):\n",
    "    print('This is not a racist or sexist tweet')\n",
    "else:\n",
    "    print('This is a racist or sexist tweet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27343629-fb13-4b35-9282-cb1ab4768012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610499c7-2168-4488-b4f1-273f7f089256",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
